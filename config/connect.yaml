http:
  enabled: false
  address: 0.0.0.0:4195
  root_path: /benthos
  debug_endpoints: false
  cert_file: ""
  key_file: ""
  cors:
    enabled: false
    allowed_origins: []
  basic_auth:
    enabled: false
    realm: restricted
    username: ""
    password_hash: ""
    algorithm: sha256
    salt: ""
input:
  label: localstack
  aws_s3:
    bucket: demobucket
    region: us-east-1
    endpoint: http://localstack:4566
    credentials:
      id: AKIAIOSFODNN7EXAMPLE # trunk-ignore(checkov/CKV_SECRET_2)
      secret: wJalrXUtnFEMIK7MDENGbPxRfiCYEXAMPLEKEY # trunk-ignore(checkov/CKV_SECRET_6)
    force_path_style_urls: true
    delete_objects: false
    sqs:
      url: http://localstack:4566/000000000000/demoqueue
      key_path: Records.*.s3.object.key
      bucket_path: Records.*.s3.bucket.name
      max_messages: 10
    scanner:
      to_the_end: {}
buffer:
  none: {}
pipeline:
  threads: -1
  processors:
    - mapping: |
        map to_json {
        let header = this.header
        let row = this.row
        root = match $row.index(0) {
            "D" => {"payload": $header.zip($row.slice(1)).map_each(r -> {r.index(0): r.index(1)}).squash()}
            "T" => {"metadata":{"count": $row.index(1), "org": $row.index(2), "timestamp": $row.index(3).ts_unix_milli(), "is_summary": true}}
            _ => deleted() #junk
          }    
        }

        map apply_metadata {
          let metadata = this.metadata
          root.payload = this.payload
          root.payload.dateOfBirth = root.payload.dateOfBirth.ts_strptime("%Y-%m-%d").ts_unix()
          root.metadata = $metadata.map_each(r -> r).filter(r -> r.org == root.payload.org).index(0)
          root.metadata.batchId = this.batchId
          root.metadata.org = deleted()
          root.metadata.is_summary = deleted()
        }

        let batchId = content().split("\n").map_each(r -> r.string()).index(0).split("|").index(1).number()
        let data = content().split("\n").map_each(r -> r.string()).slice(1)

        let header = $data.index(0).split("|").slice(1)

        let data = $data.slice(1).map_each(r -> {"header": $header, "row": r.split("|")}.apply("to_json"))
        let payloads = $data.map_each(r -> r.payload).filter(r -> r.exists("org"))
        let metadata = $data.map_each(r -> r.metadata).filter(r -> r.is_summary == true)

        root = $payloads.map_each(r -> {"payload": r, "metadata": $metadata, "batchId": $batchId}.apply("apply_metadata"))
    - unarchive:
        format: json_array
    - mapping: |
        meta kafka_key = this.payload.identityNumber.string()
    - schema_registry_encode:
        url: http://redpanda:8081
        subject: demo-value
        refresh_period: 10m
    # - catch:
    #     - log:
    #         message: ${! error()}
output:
  fallback:
    - reject_errored:
        kafka_franz:
          seed_brokers:
            - redpanda:9092
          topic: demo
          key: ${! metadata("kafka_key") }
          metadata:
            include_prefixes:
              - .*payload.*
    - kafka_franz:
          seed_brokers:
            - redpanda:9092
          topic: demo-dlq
input_resources: []
processor_resources: []
output_resources: []
cache_resources: []
rate_limit_resources: []
logger:
  level: INFO
  format: logfmt
  add_timestamp: false
  level_name: level
  timestamp_name: time
  message_name: msg
  static_fields:
    "@service": benthos
  file:
    path: ""
    rotate: false
    rotate_max_age_days: 0
metrics:
  prometheus: {}
  mapping: ""
tracer:
  none: {}
shutdown_delay: 0s
shutdown_timeout: 20s
tests: []
redpanda:
  seed_brokers: [redpanda:9092]
  logs_topic: __redpanda.connect.logs
  logs_level: info
  client_id: benthos
  rack_id: ""
  timeout: 10s
  max_message_bytes: 1MB
  tls:
    enabled: false
    skip_cert_verify: false
    enable_renegotiation: false
    root_cas: ""
    root_cas_file: ""
    client_certs: []
  sasl: []
